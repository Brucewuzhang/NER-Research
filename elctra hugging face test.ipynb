{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dd1d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFElectraForPreTraining, ElectraTokenizerFast, TFElectraModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfd2f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c73eed0debf4b28b2fa980e122e1784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf1c4cb3e514a7981c54fa18e5b3ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFElectraForPreTraining.\n",
      "\n",
      "All the layers of TFElectraForPreTraining were initialized from the model checkpoint at google/electra-base-discriminator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForPreTraining for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "discriminator = TFElectraForPreTraining.from_pretrained('google/electra-base-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ec39fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-discriminator were not used when initializing TFElectraModel: ['discriminator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-discriminator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "discriminator = TFElectraModel.from_pretrained('google/electra-base-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4faac15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4850b5d271f54e26abf107e673d10bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bcbfcec3584363a6d21b8a79495a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e7e27a21a7437c8e14e7cf3a088b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = ElectraTokenizerFast.from_pretrained('google/electra-base-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "058e7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "fake_sentence = \"The quick brown fox fake over the lazy dog.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2bdce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tokens = tokenizer.tokenize(fake_sentence)\n",
    "fake_inputs = tokenizer.encode(fake_sentence, return_tensors=\"tf\")\n",
    "discriminator_outputs = discriminator(fake_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ed3cd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'quick', 'brown', 'fox', 'fake', 'over', 'the', 'lazy', 'dog', '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20f0a82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12), dtype=int32, numpy=\n",
       "array([[  101,  1996,  4248,  2829,  4419,  8275,  2058,  1996, 13971,\n",
       "         3899,  1012,   102]], dtype=int32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "184c7a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
       "array([[[ 9.6605003e-02,  1.8004487e-01,  2.6683185e-01, ...,\n",
       "         -2.8313506e-01, -1.4175457e-01,  5.8720309e-01],\n",
       "        [ 2.2979166e-01, -1.7522274e-03,  5.0066400e-01, ...,\n",
       "         -2.7841184e-01, -3.2000989e-04,  4.8079431e-02],\n",
       "        [ 1.4820239e-01, -1.3070701e-02, -7.1553931e-02, ...,\n",
       "         -2.3992544e-01,  5.2983499e-01, -2.8049761e-01],\n",
       "        ...,\n",
       "        [ 3.8738757e-01, -2.2132413e-01,  2.8891733e-01, ...,\n",
       "         -2.5143901e-01,  1.3791977e-01, -3.9882088e-01],\n",
       "        [ 9.8925859e-02, -4.1426352e-01,  7.0701402e-01, ...,\n",
       "         -8.9888357e-02, -6.5600550e-01,  5.7955188e-01],\n",
       "        [ 9.6604846e-02,  1.8004549e-01,  2.6683167e-01, ...,\n",
       "         -2.8313538e-01, -1.4175455e-01,  5.8720410e-01]]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31271b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
